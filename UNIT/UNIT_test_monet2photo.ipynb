{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "UNIT_test_monet2photo",
      "provenance": [],
      "collapsed_sections": [
        "xNhdCuKltCS6"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hpc-vvFR0XgA"
      },
      "source": [
        "### Installations"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "btDJvhWz0QOw"
      },
      "source": [
        "%%capture\n",
        "!pip install torchfile \n",
        "!pip install tensorboardX\n",
        "!pip install pytorch-fid \n",
        "import os"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-QUd07S30a2T"
      },
      "source": [
        "## Git operations"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5lH8s21S0cEm",
        "outputId": "2e3c4f22-1ea1-494a-e3c3-f67452da704c"
      },
      "source": [
        "# Clone git repository \n",
        "!git clone 'https://github.com/XkunW/Image_Translation.git'"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'Image_Translation'...\n",
            "remote: Enumerating objects: 381, done.\u001b[K\n",
            "remote: Counting objects: 100% (89/89), done.\u001b[K\n",
            "remote: Compressing objects: 100% (66/66), done.\u001b[K\n",
            "remote: Total 381 (delta 50), reused 53 (delta 23), pack-reused 292\u001b[K\n",
            "Receiving objects: 100% (381/381), 382.56 MiB | 25.55 MiB/s, done.\n",
            "Resolving deltas: 100% (157/157), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AKx40v7f0ee-",
        "outputId": "d3ef2f91-5780-4c86-e803-0485d4b1c805"
      },
      "source": [
        "! git pull\n",
        "# ! git status\n",
        "# ! git checkout utils.py"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fatal: not a git repository (or any of the parent directories): .git\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8MTnFEZnn_jI"
      },
      "source": [
        "Clone for calculating FID score"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XloUZkh_n52-"
      },
      "source": [
        "# !git clone 'https://github.com/mseitzer/pytorch-fid.git'\n",
        "# ! git pull"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cite4Lb40igJ"
      },
      "source": [
        "## Drive mounting and unzipping data "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TcbCXfQK0gXx",
        "outputId": "928e9355-c349-441a-cca2-811ad6416d7d"
      },
      "source": [
        "# Mount drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "data_dir = '/content/drive/MyDrive/CSC2516_Project/Datasets/' #same for Tina and Sophie\n",
        "\n",
        "# data zip \n",
        "summer2winter = data_dir+'summer2winter_yosemite_small_dataset.zip' \n",
        "monet2photo = data_dir+'monet2photo_small_dataset.zip'"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "KDa-_NxI01Uc",
        "outputId": "454be00d-2440-4d2d-fb60-3acde05fbc54"
      },
      "source": [
        "# change to UNIT folder\n",
        "#%cd '/content/Image_Translation/UNIT'\n",
        "os.chdir('Image_Translation/UNIT')\n",
        "os.getcwd()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/content/Image_Translation/UNIT'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vGiX7Mn98mcm"
      },
      "source": [
        "# Unzipping datasets to the target folder\n",
        "%%capture\n",
        "# !unzip \"$summer2winter\" -d '/content/Image_Translation/UNIT/datasets/'\n",
        "!unzip \"$monet2photo\" -d '/content/Image_Translation/UNIT/datasets/'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "05KtCaXG8m2Z"
      },
      "source": [
        "# copy vgg16 model weights into the models folder in github repo\n",
        "!cp \"/content/drive/MyDrive/CSC2516_Project/UNIT_colab/VGG_model/vgg16.weight\" \"/content/Image_Translation/UNIT/models\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xNhdCuKltCS6"
      },
      "source": [
        "## Functions for FID score"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RGSzzPJXtE-S"
      },
      "source": [
        "import os\n",
        "import pathlib\n",
        "from argparse import ArgumentDefaultsHelpFormatter, ArgumentParser\n",
        "from multiprocessing import cpu_count\n",
        "import numpy as np\n",
        "import torch\n",
        "import torchvision.transforms as TF\n",
        "from PIL import Image\n",
        "from scipy import linalg\n",
        "from torch.nn.functional import adaptive_avg_pool2d\n",
        "# try:\n",
        "#     from tqdm import tqdm\n",
        "# except ImportError:\n",
        "#     # If tqdm is not available, provide a mock version of it\n",
        "#     def tqdm(x):\n",
        "#         return x\n",
        "\n",
        "from pytorch_fid.inception import InceptionV3\n",
        "\n",
        "IMAGE_EXTENSIONS = {'bmp', 'jpg', 'jpeg', 'pgm', 'png', 'ppm',\n",
        "                    'tif', 'tiff', 'webp'}\n",
        "\n",
        "class ImagePathDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, files, transforms=None):\n",
        "        self.files = files\n",
        "        self.transforms = transforms\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.files)\n",
        "\n",
        "    def __getitem__(self, i):\n",
        "        path = self.files[i]\n",
        "        img = Image.open(path).convert('RGB')\n",
        "        if self.transforms is not None:\n",
        "            img = self.transforms(img)\n",
        "        return img\n",
        "\n",
        "def get_activations(files, model, batch_size=50, dims=2048, device='cpu'):\n",
        "    model.eval()\n",
        "\n",
        "    if batch_size > len(files):\n",
        "        print(('Warning: batch size is bigger than the data size. '\n",
        "               'Setting batch size to data size'))\n",
        "        batch_size = len(files)\n",
        "\n",
        "    dataset = ImagePathDataset(files, transforms=TF.ToTensor())\n",
        "    dataloader = torch.utils.data.DataLoader(dataset,\n",
        "                                             batch_size=batch_size,\n",
        "                                             shuffle=False,\n",
        "                                             drop_last=False,\n",
        "                                             num_workers=cpu_count())\n",
        "\n",
        "    pred_arr = np.empty((len(files), dims))\n",
        "\n",
        "    start_idx = 0\n",
        "\n",
        "    for batch in dataloader: #tqdm():\n",
        "        batch = batch.to(device)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            pred = model(batch)[0]\n",
        "\n",
        "        # If model output is not scalar, apply global spatial average pooling.\n",
        "        # This happens if you choose a dimensionality not equal 2048.\n",
        "        if pred.size(2) != 1 or pred.size(3) != 1:\n",
        "            pred = adaptive_avg_pool2d(pred, output_size=(1, 1))\n",
        "\n",
        "        pred = pred.squeeze(3).squeeze(2).cpu().numpy()\n",
        "\n",
        "        pred_arr[start_idx:start_idx + pred.shape[0]] = pred\n",
        "\n",
        "        start_idx = start_idx + pred.shape[0]\n",
        "\n",
        "    return pred_arr\n",
        "\n",
        "def calculate_frechet_distance(mu1, sigma1, mu2, sigma2, eps=1e-6):\n",
        "    mu1 = np.atleast_1d(mu1)\n",
        "    mu2 = np.atleast_1d(mu2)\n",
        "    sigma1 = np.atleast_2d(sigma1)\n",
        "    sigma2 = np.atleast_2d(sigma2)\n",
        "\n",
        "    assert mu1.shape == mu2.shape, \\\n",
        "        'Training and test mean vectors have different lengths'\n",
        "    assert sigma1.shape == sigma2.shape, \\\n",
        "        'Training and test covariances have different dimensions'\n",
        "\n",
        "    diff = mu1 - mu2\n",
        "\n",
        "    # Product might be almost singular\n",
        "    covmean, _ = linalg.sqrtm(sigma1.dot(sigma2), disp=False)\n",
        "    if not np.isfinite(covmean).all():\n",
        "        msg = ('fid calculation produces singular product; '\n",
        "               'adding %s to diagonal of cov estimates') % eps\n",
        "        print(msg)\n",
        "        offset = np.eye(sigma1.shape[0]) * eps\n",
        "        covmean = linalg.sqrtm((sigma1 + offset).dot(sigma2 + offset))\n",
        "\n",
        "    # Numerical error might give slight imaginary component\n",
        "    if np.iscomplexobj(covmean):\n",
        "        if not np.allclose(np.diagonal(covmean).imag, 0, atol=1e-3):\n",
        "            m = np.max(np.abs(covmean.imag))\n",
        "            raise ValueError('Imaginary component {}'.format(m))\n",
        "        covmean = covmean.real\n",
        "\n",
        "    tr_covmean = np.trace(covmean)\n",
        "\n",
        "    return (diff.dot(diff) + np.trace(sigma1)\n",
        "            + np.trace(sigma2) - 2 * tr_covmean)\n",
        "\n",
        "\n",
        "def calculate_activation_statistics(files, model, batch_size=50, dims=2048,\n",
        "                                    device='cpu'):\n",
        "    act = get_activations(files, model, batch_size, dims, device)\n",
        "    mu = np.mean(act, axis=0)\n",
        "    sigma = np.cov(act, rowvar=False)\n",
        "    return mu, sigma\n",
        "\n",
        "\n",
        "def compute_statistics_of_path(path, model, batch_size, dims, device):\n",
        "    if path.endswith('.npz'):\n",
        "        with np.load(path) as f:\n",
        "            m, s = f['mu'][:], f['sigma'][:]\n",
        "    else:\n",
        "        path = pathlib.Path(path)\n",
        "        files = sorted([file for ext in IMAGE_EXTENSIONS\n",
        "                       for file in path.glob('*.{}'.format(ext))])\n",
        "        m, s = calculate_activation_statistics(files, model, batch_size,\n",
        "                                               dims, device)\n",
        "\n",
        "    return m, s\n",
        "\n",
        "\n",
        "def calculate_fid_given_paths(paths, batch_size, device, dims):\n",
        "    \"\"\"Calculates the FID of two paths\"\"\"\n",
        "    for p in paths:\n",
        "        if not os.path.exists(p):\n",
        "            raise RuntimeError('Invalid path: %s' % p)\n",
        "\n",
        "    block_idx = InceptionV3.BLOCK_INDEX_BY_DIM[dims]\n",
        "\n",
        "    model = InceptionV3([block_idx]).to(device)\n",
        "\n",
        "    m1, s1 = compute_statistics_of_path(paths[0], model, batch_size,\n",
        "                                        dims, device)\n",
        "    m2, s2 = compute_statistics_of_path(paths[1], model, batch_size,\n",
        "                                        dims, device)\n",
        "    fid_value = calculate_frechet_distance(m1, s1, m2, s2)\n",
        "\n",
        "    return fid_value\n",
        "\n",
        "def get_fid(batch_size, dims, path):\n",
        "    device = torch.device('cuda' if (torch.cuda.is_available()) else 'cpu')\n",
        "    fid_value = calculate_fid_given_paths(path,\n",
        "                                          batch_size,\n",
        "                                          device,\n",
        "                                          dims)\n",
        "    return fid_value"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P2WrDDhK9tT4"
      },
      "source": [
        "## Test code"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WvwKFKsf4um6"
      },
      "source": [
        "# test code, to read model and generate images \n",
        "from __future__ import print_function\n",
        "import argparse\n",
        "import os\n",
        "import torch\n",
        "import torchvision.utils as vutils\n",
        "from PIL import Image\n",
        "import pandas as pd\n",
        "from torch.autograd import Variable\n",
        "from torchvision import transforms\n",
        "from trainer import UNIT_Trainer\n",
        "from utils import get_config, pytorch03_to_pytorch04\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Snmpk6WIRP3T"
      },
      "source": [
        "def generate_save_image(input, style, output_folder, file_name):\n",
        "  # currently passed in one image, need to loop through images\n",
        "    if torch.cuda.is_available():\n",
        "        image = Variable(transform(Image.open(input).convert('RGB')).unsqueeze(0).cuda())\n",
        "        style_image = Variable(\n",
        "            transform(Image.open(style).convert('RGB')).unsqueeze(0).cuda()) if style != '' else None\n",
        "    else:\n",
        "        image = Variable(transform(Image.open(input).convert('RGB')).unsqueeze(0))\n",
        "        style_image = Variable(\n",
        "            transform(Image.open(style).convert('RGB')).unsqueeze(0)) if style != '' else None\n",
        "\n",
        "    # Start testing - generate, need to change the image name later too\n",
        "    content, _ = encode(image)\n",
        "    outputs = decode(content)\n",
        "    outputs = (outputs + 1) / 2.\n",
        "    path = os.path.join(output_folder, file_name) #'output.jpg'\n",
        "    vutils.save_image(outputs.data, path, padding=0, normalize=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tv6DCfvw-wHA"
      },
      "source": [
        "### Generate FID score table saving temporary images "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gqclqASq-06T"
      },
      "source": [
        "# arguments\n",
        "# --input inputs/gta_example.jpg --output_folder results/gta2city --checkpoint models/unit_gta2city.pt\n",
        "\n",
        "checkpoint_dir_summer2winter = '/content/drive/MyDrive/CSC2516_Project/UNIT_summer2winter_small/outputs/unit_summer2winter_yosemite256_folder/checkpoints/'\n",
        "checkpoint_dir_monet2photo = '/content/drive/MyDrive/CSC2516_Project/UNIT_monet2photo_small/outputs/unit_monet2photo_folder/checkpoints/'\n",
        "\n",
        "# 'configs/unit_summer2winter_yosemite256_list.yaml'\n",
        "config_file =  'configs/unit_monet2photo_list.yaml'\n",
        "output_folder = 'results/monet2photo' # need name addon\n",
        "csv_output_folder = '/content/drive/MyDrive/CSC2516_Project/UNIT_monet2photo_small/results/'\n",
        "checkpoint = checkpoint_dir_monet2photo # or checkpoint_dir_monet2photo , need name add on \n",
        "output_only = True #only saving the generated image output\n",
        "\n",
        "parser = argparse.ArgumentParser()\n",
        "parser.add_argument('--config', type=str, default=config_file, help=\"net configuration\")\n",
        "parser.add_argument('--style', type=str, default='', help=\"style image path\")\n",
        "# parser.add_argument('--a2b', type=int, default=1, help=\"1 for a2b and others for b2a\")\n",
        "parser.add_argument('--seed', type=int, default=10, help=\"random seed\")\n",
        "parser.add_argument('--num_style', type=int, default=10, help=\"number of styles to sample\")\n",
        "parser.add_argument('--synchronized', action='store_true', help=\"whether use synchronized style code or not\")\n",
        "parser.add_argument('--output_folder', type=str, default=output_folder, help=\"output image path\")\n",
        "# parser.add_argument('--output_only', action='store_true', help=\"whether use synchronized style code or not\")\n",
        "parser.add_argument('--output_path', type=str, default='.', help=\"path for logs, checkpoints, and VGG model weight\")\n",
        "parser.add_argument('--trainer', type=str, default='UNIT', help=\"UNIT\")\n",
        "parser.add_argument('-f', default='')\n",
        "opts = parser.parse_args()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_drH8b3toHI_",
        "outputId": "630251de-5b60-4534-b992-1273b34e8620"
      },
      "source": [
        "# manual set up hps, iterate through iteration numbers\n",
        "recon_kl_cyc_w_list = [0.01, 0.1]\n",
        "lr_values = [0.0001, 0.0005]\n",
        "iterations = ['00008000', '00016000', '00024000', '00032000', '00040000', \n",
        "              '00048000', '00056000', '00064000', '00072000', '00080000']\n",
        "\n",
        "# load existing csv table or create new \n",
        "try:\n",
        "    FID_table = pd.read_csv(csv_output_folder + 'FID.csv')\n",
        "except: \n",
        "    FID_table =  pd.DataFrame(columns=['recon_kl_w', 'recon_kl_clc', 'lr_value', 'iteration', \n",
        "                                   'fid_val_A2B', 'fid_val_A2B2A', 'fid_val_B2A',\n",
        "                                   'fid_val_B2A2B'])\n",
        "torch.manual_seed(opts.seed)\n",
        "if torch.cuda.is_available():\n",
        "    torch.cuda.manual_seed(opts.seed)\n",
        "\n",
        "config = get_config(opts.config)\n",
        "\n",
        "# global definition \n",
        "input_folder = config['data_root']\n",
        "input_folder_A = input_folder + '/testA/'\n",
        "input_folder_B = input_folder + '/testB/'\n",
        "\n",
        "# iterate through different iterations\n",
        "for lr_value in lr_values:\n",
        "    for recon_kl_cyc_w in recon_kl_cyc_w_list:\n",
        "        recon_kl_w = recon_kl_cyc_w\n",
        "        for iter in iterations: \n",
        "            param_values = 'kl_w_' + str(recon_kl_w) + 'kl_clc_'+ str(recon_kl_cyc_w)  + '_lr_valie_' + str(lr_value)\n",
        "            current_output_A2B = opts.output_folder + '/A2B/' + param_values + '/'\n",
        "            current_output_A2B2A = opts.output_folder + '/A2B2A/' + param_values + '/'\n",
        "            current_output_B2A = opts.output_folder + '/B2A/' + param_values + '/'\n",
        "            current_output_B2A2B = opts.output_folder + '/B2A2B/' + param_values + '/'\n",
        "            local_string = 'gen_'+ str(iter) + '_batch_size_1_recon_kl_w_' \\\n",
        "                                        + str(recon_kl_w) + '_recon_kl_clc_' \\\n",
        "                                        + str(recon_kl_cyc_w)  + '_lr_value_' + str(lr_value) + '.pt'\n",
        "            current_checkpoint = os.path.join(checkpoint, local_string)\n",
        "            print(current_checkpoint)\n",
        "\n",
        "            # create output folder path \n",
        "            if not os.path.exists(opts.output_folder):\n",
        "                os.makedirs(opts.output_folder)\n",
        "            if not os.path.exists(current_output_A2B):\n",
        "                os.makedirs(current_output_A2B)\n",
        "            if not os.path.exists(current_output_A2B2A):\n",
        "                os.makedirs(current_output_A2B2A)\n",
        "            if not os.path.exists(current_output_B2A):\n",
        "                os.makedirs(current_output_B2A)\n",
        "            if not os.path.exists(current_output_B2A2B):\n",
        "                os.makedirs(current_output_B2A2B)\n",
        "\n",
        "            # Load experiment setting, modify config value \n",
        "            config = get_config(opts.config)\n",
        "            opts.num_style = 1 if opts.style != '' else opts.num_style\n",
        "\n",
        "            # Setup model and data loader\n",
        "            config['vgg_model_path'] = '.'\n",
        "\n",
        "            # loop through a2b and b2a \n",
        "            for a2b in [True, False]:\n",
        "                trainer = UNIT_Trainer(config)\n",
        "                try:\n",
        "                    state_dict = torch.load(current_checkpoint)\n",
        "                    trainer.gen_a.load_state_dict(state_dict['a'])\n",
        "                    trainer.gen_b.load_state_dict(state_dict['b'])\n",
        "                except:\n",
        "                    state_dict = pytorch03_to_pytorch04(torch.load(current_checkpoint))\n",
        "                    trainer.gen_a.load_state_dict(state_dict['a'])\n",
        "                    trainer.gen_b.load_state_dict(state_dict['b'])\n",
        "\n",
        "                if torch.cuda.is_available():\n",
        "                    trainer.cuda()\n",
        "                trainer.eval()\n",
        "                encode = trainer.gen_a.encode if a2b else trainer.gen_b.encode  # encode function\n",
        "                style_encode = trainer.gen_b.encode if a2b else trainer.gen_a.encode  # encode function\n",
        "                decode = trainer.gen_b.decode if a2b else trainer.gen_a.decode  # decode function\n",
        "\n",
        "                if 'new_size' in config:\n",
        "                    new_size = config['new_size']\n",
        "                else:\n",
        "                    if a2b:\n",
        "                        new_size = config['new_size_a']\n",
        "                    else:\n",
        "                        new_size = config['new_size_b']\n",
        "\n",
        "                with torch.no_grad():\n",
        "                    transform = transforms.Compose([transforms.Resize(new_size),\n",
        "                                                    transforms.ToTensor(),\n",
        "                                                    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "                    if a2b:\n",
        "                        # 1. Generate images A -> B\n",
        "                        image_list_A = os.listdir(input_folder_A)  # list of images inside A folder\n",
        "                        for input_image in image_list_A:\n",
        "                            generate_save_image(input_folder_A+input_image, opts.style, current_output_A2B, input_image)\n",
        "\n",
        "                        # 2. Generate images A -> B -> A\n",
        "                        image_list_A2B = os.listdir(current_output_A2B)  # list of images inside A2B folder\n",
        "                        for input_image in image_list_A2B:\n",
        "                            generate_save_image(current_output_A2B+input_image, opts.style, current_output_A2B2A, input_image)\n",
        "                        \n",
        "                    else:\n",
        "                        # 1. Generate images B -> A\n",
        "                        image_list_B = os.listdir(input_folder_B)  # list of images inside B folder\n",
        "                        for input_image in image_list_B:\n",
        "                            generate_save_image(input_folder_B+input_image, opts.style, current_output_B2A, input_image)\n",
        "\n",
        "                        # 2. Generate images B -> A -> B\n",
        "                        image_list_B2A = os.listdir(current_output_B2A)  # list of images inside B2A folder\n",
        "                        for input_image in image_list_B2A:\n",
        "                            generate_save_image(current_output_B2A+input_image, opts.style, current_output_B2A2B, input_image)\n",
        "\n",
        "                \n",
        "                    # compute fid score \n",
        "                    if a2b:\n",
        "                        # 1. compare A2B with testB\n",
        "                        fid_val_A2B = get_fid(batch_size=1, dims=2048, path=[current_output_A2B, input_folder_B])\n",
        "\n",
        "                        # 2. compare A2B2A with testA\n",
        "                        fid_val_A2B2A = get_fid(batch_size=1, dims=2048, path=[current_output_A2B2A,input_folder_A])\n",
        "\n",
        "                    else:\n",
        "                        # 3. compare B2A with test A\n",
        "                        fid_val_B2A = get_fid(batch_size=1, dims=2048, path=[current_output_B2A, input_folder_A])\n",
        "\n",
        "                        # 4. compare B2A2B with test B\n",
        "                        fid_val_B2A2B = get_fid(batch_size=1, dims=2048, path=[current_output_B2A2B, input_folder_B])\n",
        "\n",
        "            # append record after generating both A2B and B2A results \n",
        "            current_fid = {\n",
        "                'fid_val_A2B': fid_val_A2B,\n",
        "                'fid_val_A2B2A': fid_val_A2B2A,\n",
        "                'fid_val_B2A': fid_val_B2A,\n",
        "                'fid_val_B2A2B': fid_val_B2A2B,\n",
        "                'recon_kl_w': recon_kl_w,\n",
        "                'recon_kl_clc': recon_kl_cyc_w,\n",
        "                'lr_value': lr_value,\n",
        "                'iteration': iter\n",
        "                }\n",
        "\n",
        "            FID_table = FID_table.append(current_fid, ignore_index=True)\n",
        "\n",
        "        # save after each iteration \n",
        "        FID_table.to_csv(csv_output_folder + 'FID.csv', index=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/CSC2516_Project/UNIT_monet2photo_small/outputs/unit_monet2photo_folder/checkpoints/gen_00008000_batch_size_1_recon_kl_w_0.01_recon_kl_clc_0.01_lr_value_0.0001.pt\n",
            "/content/drive/MyDrive/CSC2516_Project/UNIT_monet2photo_small/outputs/unit_monet2photo_folder/checkpoints/gen_00016000_batch_size_1_recon_kl_w_0.01_recon_kl_clc_0.01_lr_value_0.0001.pt\n",
            "/content/drive/MyDrive/CSC2516_Project/UNIT_monet2photo_small/outputs/unit_monet2photo_folder/checkpoints/gen_00024000_batch_size_1_recon_kl_w_0.01_recon_kl_clc_0.01_lr_value_0.0001.pt\n",
            "/content/drive/MyDrive/CSC2516_Project/UNIT_monet2photo_small/outputs/unit_monet2photo_folder/checkpoints/gen_00032000_batch_size_1_recon_kl_w_0.01_recon_kl_clc_0.01_lr_value_0.0001.pt\n",
            "/content/drive/MyDrive/CSC2516_Project/UNIT_monet2photo_small/outputs/unit_monet2photo_folder/checkpoints/gen_00040000_batch_size_1_recon_kl_w_0.01_recon_kl_clc_0.01_lr_value_0.0001.pt\n",
            "/content/drive/MyDrive/CSC2516_Project/UNIT_monet2photo_small/outputs/unit_monet2photo_folder/checkpoints/gen_00048000_batch_size_1_recon_kl_w_0.01_recon_kl_clc_0.01_lr_value_0.0001.pt\n",
            "/content/drive/MyDrive/CSC2516_Project/UNIT_monet2photo_small/outputs/unit_monet2photo_folder/checkpoints/gen_00056000_batch_size_1_recon_kl_w_0.01_recon_kl_clc_0.01_lr_value_0.0001.pt\n",
            "/content/drive/MyDrive/CSC2516_Project/UNIT_monet2photo_small/outputs/unit_monet2photo_folder/checkpoints/gen_00064000_batch_size_1_recon_kl_w_0.01_recon_kl_clc_0.01_lr_value_0.0001.pt\n",
            "/content/drive/MyDrive/CSC2516_Project/UNIT_monet2photo_small/outputs/unit_monet2photo_folder/checkpoints/gen_00072000_batch_size_1_recon_kl_w_0.01_recon_kl_clc_0.01_lr_value_0.0001.pt\n",
            "/content/drive/MyDrive/CSC2516_Project/UNIT_monet2photo_small/outputs/unit_monet2photo_folder/checkpoints/gen_00080000_batch_size_1_recon_kl_w_0.01_recon_kl_clc_0.01_lr_value_0.0001.pt\n",
            "/content/drive/MyDrive/CSC2516_Project/UNIT_monet2photo_small/outputs/unit_monet2photo_folder/checkpoints/gen_00008000_batch_size_1_recon_kl_w_0.1_recon_kl_clc_0.1_lr_value_0.0001.pt\n",
            "/content/drive/MyDrive/CSC2516_Project/UNIT_monet2photo_small/outputs/unit_monet2photo_folder/checkpoints/gen_00016000_batch_size_1_recon_kl_w_0.1_recon_kl_clc_0.1_lr_value_0.0001.pt\n",
            "/content/drive/MyDrive/CSC2516_Project/UNIT_monet2photo_small/outputs/unit_monet2photo_folder/checkpoints/gen_00024000_batch_size_1_recon_kl_w_0.1_recon_kl_clc_0.1_lr_value_0.0001.pt\n",
            "/content/drive/MyDrive/CSC2516_Project/UNIT_monet2photo_small/outputs/unit_monet2photo_folder/checkpoints/gen_00032000_batch_size_1_recon_kl_w_0.1_recon_kl_clc_0.1_lr_value_0.0001.pt\n",
            "/content/drive/MyDrive/CSC2516_Project/UNIT_monet2photo_small/outputs/unit_monet2photo_folder/checkpoints/gen_00040000_batch_size_1_recon_kl_w_0.1_recon_kl_clc_0.1_lr_value_0.0001.pt\n",
            "/content/drive/MyDrive/CSC2516_Project/UNIT_monet2photo_small/outputs/unit_monet2photo_folder/checkpoints/gen_00048000_batch_size_1_recon_kl_w_0.1_recon_kl_clc_0.1_lr_value_0.0001.pt\n",
            "/content/drive/MyDrive/CSC2516_Project/UNIT_monet2photo_small/outputs/unit_monet2photo_folder/checkpoints/gen_00056000_batch_size_1_recon_kl_w_0.1_recon_kl_clc_0.1_lr_value_0.0001.pt\n",
            "/content/drive/MyDrive/CSC2516_Project/UNIT_monet2photo_small/outputs/unit_monet2photo_folder/checkpoints/gen_00064000_batch_size_1_recon_kl_w_0.1_recon_kl_clc_0.1_lr_value_0.0001.pt\n",
            "/content/drive/MyDrive/CSC2516_Project/UNIT_monet2photo_small/outputs/unit_monet2photo_folder/checkpoints/gen_00072000_batch_size_1_recon_kl_w_0.1_recon_kl_clc_0.1_lr_value_0.0001.pt\n",
            "/content/drive/MyDrive/CSC2516_Project/UNIT_monet2photo_small/outputs/unit_monet2photo_folder/checkpoints/gen_00080000_batch_size_1_recon_kl_w_0.1_recon_kl_clc_0.1_lr_value_0.0001.pt\n",
            "/content/drive/MyDrive/CSC2516_Project/UNIT_monet2photo_small/outputs/unit_monet2photo_folder/checkpoints/gen_00008000_batch_size_1_recon_kl_w_0.01_recon_kl_clc_0.01_lr_value_0.0005.pt\n",
            "/content/drive/MyDrive/CSC2516_Project/UNIT_monet2photo_small/outputs/unit_monet2photo_folder/checkpoints/gen_00016000_batch_size_1_recon_kl_w_0.01_recon_kl_clc_0.01_lr_value_0.0005.pt\n",
            "/content/drive/MyDrive/CSC2516_Project/UNIT_monet2photo_small/outputs/unit_monet2photo_folder/checkpoints/gen_00024000_batch_size_1_recon_kl_w_0.01_recon_kl_clc_0.01_lr_value_0.0005.pt\n",
            "/content/drive/MyDrive/CSC2516_Project/UNIT_monet2photo_small/outputs/unit_monet2photo_folder/checkpoints/gen_00032000_batch_size_1_recon_kl_w_0.01_recon_kl_clc_0.01_lr_value_0.0005.pt\n",
            "/content/drive/MyDrive/CSC2516_Project/UNIT_monet2photo_small/outputs/unit_monet2photo_folder/checkpoints/gen_00040000_batch_size_1_recon_kl_w_0.01_recon_kl_clc_0.01_lr_value_0.0005.pt\n",
            "/content/drive/MyDrive/CSC2516_Project/UNIT_monet2photo_small/outputs/unit_monet2photo_folder/checkpoints/gen_00048000_batch_size_1_recon_kl_w_0.01_recon_kl_clc_0.01_lr_value_0.0005.pt\n",
            "/content/drive/MyDrive/CSC2516_Project/UNIT_monet2photo_small/outputs/unit_monet2photo_folder/checkpoints/gen_00056000_batch_size_1_recon_kl_w_0.01_recon_kl_clc_0.01_lr_value_0.0005.pt\n",
            "/content/drive/MyDrive/CSC2516_Project/UNIT_monet2photo_small/outputs/unit_monet2photo_folder/checkpoints/gen_00064000_batch_size_1_recon_kl_w_0.01_recon_kl_clc_0.01_lr_value_0.0005.pt\n",
            "/content/drive/MyDrive/CSC2516_Project/UNIT_monet2photo_small/outputs/unit_monet2photo_folder/checkpoints/gen_00072000_batch_size_1_recon_kl_w_0.01_recon_kl_clc_0.01_lr_value_0.0005.pt\n",
            "/content/drive/MyDrive/CSC2516_Project/UNIT_monet2photo_small/outputs/unit_monet2photo_folder/checkpoints/gen_00080000_batch_size_1_recon_kl_w_0.01_recon_kl_clc_0.01_lr_value_0.0005.pt\n",
            "/content/drive/MyDrive/CSC2516_Project/UNIT_monet2photo_small/outputs/unit_monet2photo_folder/checkpoints/gen_00008000_batch_size_1_recon_kl_w_0.1_recon_kl_clc_0.1_lr_value_0.0005.pt\n",
            "/content/drive/MyDrive/CSC2516_Project/UNIT_monet2photo_small/outputs/unit_monet2photo_folder/checkpoints/gen_00016000_batch_size_1_recon_kl_w_0.1_recon_kl_clc_0.1_lr_value_0.0005.pt\n",
            "/content/drive/MyDrive/CSC2516_Project/UNIT_monet2photo_small/outputs/unit_monet2photo_folder/checkpoints/gen_00024000_batch_size_1_recon_kl_w_0.1_recon_kl_clc_0.1_lr_value_0.0005.pt\n",
            "/content/drive/MyDrive/CSC2516_Project/UNIT_monet2photo_small/outputs/unit_monet2photo_folder/checkpoints/gen_00032000_batch_size_1_recon_kl_w_0.1_recon_kl_clc_0.1_lr_value_0.0005.pt\n",
            "/content/drive/MyDrive/CSC2516_Project/UNIT_monet2photo_small/outputs/unit_monet2photo_folder/checkpoints/gen_00040000_batch_size_1_recon_kl_w_0.1_recon_kl_clc_0.1_lr_value_0.0005.pt\n",
            "/content/drive/MyDrive/CSC2516_Project/UNIT_monet2photo_small/outputs/unit_monet2photo_folder/checkpoints/gen_00048000_batch_size_1_recon_kl_w_0.1_recon_kl_clc_0.1_lr_value_0.0005.pt\n",
            "/content/drive/MyDrive/CSC2516_Project/UNIT_monet2photo_small/outputs/unit_monet2photo_folder/checkpoints/gen_00056000_batch_size_1_recon_kl_w_0.1_recon_kl_clc_0.1_lr_value_0.0005.pt\n",
            "/content/drive/MyDrive/CSC2516_Project/UNIT_monet2photo_small/outputs/unit_monet2photo_folder/checkpoints/gen_00064000_batch_size_1_recon_kl_w_0.1_recon_kl_clc_0.1_lr_value_0.0005.pt\n",
            "/content/drive/MyDrive/CSC2516_Project/UNIT_monet2photo_small/outputs/unit_monet2photo_folder/checkpoints/gen_00072000_batch_size_1_recon_kl_w_0.1_recon_kl_clc_0.1_lr_value_0.0005.pt\n",
            "/content/drive/MyDrive/CSC2516_Project/UNIT_monet2photo_small/outputs/unit_monet2photo_folder/checkpoints/gen_00080000_batch_size_1_recon_kl_w_0.1_recon_kl_clc_0.1_lr_value_0.0005.pt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BbUdCjbV-pf9"
      },
      "source": [
        "### Generate images only "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PZYn1AS9_Bdt"
      },
      "source": [
        "# arguments\n",
        "# --input inputs/gta_example.jpg --output_folder results/gta2city --checkpoint models/unit_gta2city.pt\n",
        "\n",
        "checkpoint_dir_summer2winter = '/content/drive/MyDrive/CSC2516_Project/UNIT_summer2winter_small/outputs/unit_summer2winter_yosemite256_folder/checkpoints/'\n",
        "checkpoint_dir_monet2photo = '/content/drive/MyDrive/CSC2516_Project/UNIT_monet2photo_small/outputs/unit_monet2photo_folder/checkpoints/'\n",
        "\n",
        "# 'configs/unit_summer2winter_yosemite256_list.yaml'\n",
        "config_file =  'configs/unit_monet2photo_list.yaml'\n",
        "output_folder = '/content/drive/MyDrive/CSC2516_Project/UNIT_monet2photo_small/results/' # need name addon\n",
        "#csv_output_folder = '/content/drive/MyDrive/CSC2516_Project/UNIT_monet2photo_small/results/'\n",
        "checkpoint = checkpoint_dir_monet2photo # or checkpoint_dir_monet2photo , need name add on \n",
        "output_only = True #only saving the generated image output\n",
        "\n",
        "parser = argparse.ArgumentParser()\n",
        "parser.add_argument('--config', type=str, default=config_file, help=\"net configuration\")\n",
        "parser.add_argument('--style', type=str, default='', help=\"style image path\")\n",
        "# parser.add_argument('--a2b', type=int, default=1, help=\"1 for a2b and others for b2a\")\n",
        "parser.add_argument('--seed', type=int, default=10, help=\"random seed\")\n",
        "parser.add_argument('--num_style', type=int, default=10, help=\"number of styles to sample\")\n",
        "parser.add_argument('--synchronized', action='store_true', help=\"whether use synchronized style code or not\")\n",
        "parser.add_argument('--output_folder', type=str, default=output_folder, help=\"output image path\")\n",
        "# parser.add_argument('--output_only', action='store_true', help=\"whether use synchronized style code or not\")\n",
        "parser.add_argument('--output_path', type=str, default='.', help=\"path for logs, checkpoints, and VGG model weight\")\n",
        "parser.add_argument('--trainer', type=str, default='UNIT', help=\"UNIT\")\n",
        "parser.add_argument('-f', default='')\n",
        "opts = parser.parse_args()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wW6WJLjP_EhG",
        "outputId": "83428ab5-4038-4d8c-e4ca-e55febf10cc3"
      },
      "source": [
        "# manual set up hps, iterate through iteration numbers\n",
        "recon_kl_cyc_w = 0.01\n",
        "recon_kl_w = 0.01\n",
        "lr_value = 0.0001\n",
        "iter = '00048000'\n",
        "\n",
        "torch.manual_seed(opts.seed)\n",
        "if torch.cuda.is_available():\n",
        "    torch.cuda.manual_seed(opts.seed)\n",
        "\n",
        "config = get_config(opts.config)\n",
        "\n",
        "# global definition \n",
        "input_folder = config['data_root']\n",
        "input_folder_A = input_folder + '/testA/'\n",
        "input_folder_B = input_folder + '/testB/'\n",
        "\n",
        "param_values = 'kl_w_' + str(recon_kl_w) + 'kl_clc_'+ str(recon_kl_cyc_w)  + '_lr_valie_' + str(lr_value)\n",
        "current_output_A2B = opts.output_folder + '/A2B/' + param_values + '/'\n",
        "current_output_A2B2A = opts.output_folder + '/A2B2A/' + param_values + '/'\n",
        "current_output_B2A = opts.output_folder + '/B2A/' + param_values + '/'\n",
        "current_output_B2A2B = opts.output_folder + '/B2A2B/' + param_values + '/'\n",
        "local_string = 'gen_'+ str(iter) + '_batch_size_1_recon_kl_w_' \\\n",
        "                            + str(recon_kl_w) + '_recon_kl_clc_' \\\n",
        "                            + str(recon_kl_cyc_w)  + '_lr_value_' + str(lr_value) + '.pt'\n",
        "\n",
        "current_checkpoint = os.path.join(checkpoint, local_string)\n",
        "print(current_checkpoint)\n",
        "\n",
        "# create output folder path \n",
        "if not os.path.exists(opts.output_folder):\n",
        "    os.makedirs(opts.output_folder)\n",
        "if not os.path.exists(current_output_A2B):\n",
        "    os.makedirs(current_output_A2B)\n",
        "if not os.path.exists(current_output_A2B2A):\n",
        "    os.makedirs(current_output_A2B2A)\n",
        "if not os.path.exists(current_output_B2A):\n",
        "    os.makedirs(current_output_B2A)\n",
        "if not os.path.exists(current_output_B2A2B):\n",
        "    os.makedirs(current_output_B2A2B)\n",
        "\n",
        "# Load experiment setting, modify config value \n",
        "config = get_config(opts.config)\n",
        "opts.num_style = 1 if opts.style != '' else opts.num_style\n",
        "\n",
        "# Setup model and data loader\n",
        "config['vgg_model_path'] = '.'\n",
        "\n",
        "# loop through a2b and b2a \n",
        "for a2b in [True, False]:\n",
        "    trainer = UNIT_Trainer(config)\n",
        "    try:\n",
        "        state_dict = torch.load(current_checkpoint)\n",
        "        trainer.gen_a.load_state_dict(state_dict['a'])\n",
        "        trainer.gen_b.load_state_dict(state_dict['b'])\n",
        "    except:\n",
        "        state_dict = pytorch03_to_pytorch04(torch.load(current_checkpoint))\n",
        "        trainer.gen_a.load_state_dict(state_dict['a'])\n",
        "        trainer.gen_b.load_state_dict(state_dict['b'])\n",
        "\n",
        "    if torch.cuda.is_available():\n",
        "        trainer.cuda()\n",
        "    trainer.eval()\n",
        "    encode = trainer.gen_a.encode if a2b else trainer.gen_b.encode  # encode function\n",
        "    style_encode = trainer.gen_b.encode if a2b else trainer.gen_a.encode  # encode function\n",
        "    decode = trainer.gen_b.decode if a2b else trainer.gen_a.decode  # decode function\n",
        "\n",
        "    if 'new_size' in config:\n",
        "        new_size = config['new_size']\n",
        "    else:\n",
        "        if a2b:\n",
        "            new_size = config['new_size_a']\n",
        "        else:\n",
        "            new_size = config['new_size_b']\n",
        "\n",
        "    with torch.no_grad():\n",
        "        transform = transforms.Compose([transforms.Resize(new_size),\n",
        "                                        transforms.ToTensor(),\n",
        "                                        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "        if a2b:\n",
        "            # 1. Generate images A -> B\n",
        "            image_list_A = os.listdir(input_folder_A)  # list of images inside A folder\n",
        "            for input_image in image_list_A:\n",
        "                generate_save_image(input_folder_A+input_image, opts.style, current_output_A2B, input_image)\n",
        "\n",
        "            # 2. Generate images A -> B -> A\n",
        "            image_list_A2B = os.listdir(current_output_A2B)  # list of images inside A2B folder\n",
        "            for input_image in image_list_A2B:\n",
        "                generate_save_image(current_output_A2B+input_image, opts.style, current_output_A2B2A, input_image)\n",
        "            \n",
        "        else:\n",
        "            # 1. Generate images B -> A\n",
        "            image_list_B = os.listdir(input_folder_B)  # list of images inside B folder\n",
        "            for input_image in image_list_B:\n",
        "                generate_save_image(input_folder_B+input_image, opts.style, current_output_B2A, input_image)\n",
        "\n",
        "            # 2. Generate images B -> A -> B\n",
        "            image_list_B2A = os.listdir(current_output_B2A)  # list of images inside B2A folder\n",
        "            for input_image in image_list_B2A:\n",
        "                generate_save_image(current_output_B2A+input_image, opts.style, current_output_B2A2B, input_image)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/CSC2516_Project/UNIT_monet2photo_small/outputs/unit_monet2photo_folder/checkpoints/gen_00048000_batch_size_1_recon_kl_w_0.01_recon_kl_clc_0.01_lr_value_0.0001.pt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cAst5GiyeQmD"
      },
      "source": [
        "### Done"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LbXVE6oahP4U",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 402
        },
        "outputId": "e7a417d4-e4a2-4fb4-9aae-d81d06080a08"
      },
      "source": [
        "FID_table = pd.read_csv(csv_output_folder + 'FID.csv')\n",
        "FID_table.reset_index().drop(columns=['index']).to_csv(csv_output_folder + 'FID.csv', index=False)\n",
        "FID_table.reset_index().drop(columns=['index'])\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>recon_kl_w</th>\n",
              "      <th>recon_kl_clc</th>\n",
              "      <th>lr_value</th>\n",
              "      <th>iteration</th>\n",
              "      <th>fid_val_A2B</th>\n",
              "      <th>fid_val_A2B2A</th>\n",
              "      <th>fid_val_B2A</th>\n",
              "      <th>fid_val_B2A2B</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.01</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.0001</td>\n",
              "      <td>8000</td>\n",
              "      <td>224.968845</td>\n",
              "      <td>210.204624</td>\n",
              "      <td>197.646804</td>\n",
              "      <td>224.168804</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.01</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.0001</td>\n",
              "      <td>16000</td>\n",
              "      <td>224.968845</td>\n",
              "      <td>210.204624</td>\n",
              "      <td>174.118954</td>\n",
              "      <td>242.698832</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.01</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.0001</td>\n",
              "      <td>24000</td>\n",
              "      <td>224.968845</td>\n",
              "      <td>210.204624</td>\n",
              "      <td>176.418824</td>\n",
              "      <td>264.287935</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.01</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.0001</td>\n",
              "      <td>32000</td>\n",
              "      <td>224.968845</td>\n",
              "      <td>210.204624</td>\n",
              "      <td>169.634462</td>\n",
              "      <td>251.724293</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.01</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.0001</td>\n",
              "      <td>40000</td>\n",
              "      <td>224.968845</td>\n",
              "      <td>210.204624</td>\n",
              "      <td>171.687572</td>\n",
              "      <td>260.475951</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>95</th>\n",
              "      <td>0.10</td>\n",
              "      <td>0.10</td>\n",
              "      <td>0.0005</td>\n",
              "      <td>48000</td>\n",
              "      <td>325.311955</td>\n",
              "      <td>328.068634</td>\n",
              "      <td>316.374747</td>\n",
              "      <td>370.030933</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>96</th>\n",
              "      <td>0.10</td>\n",
              "      <td>0.10</td>\n",
              "      <td>0.0005</td>\n",
              "      <td>56000</td>\n",
              "      <td>278.774849</td>\n",
              "      <td>277.374384</td>\n",
              "      <td>227.174077</td>\n",
              "      <td>328.726003</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>97</th>\n",
              "      <td>0.10</td>\n",
              "      <td>0.10</td>\n",
              "      <td>0.0005</td>\n",
              "      <td>64000</td>\n",
              "      <td>330.886296</td>\n",
              "      <td>308.776254</td>\n",
              "      <td>198.270536</td>\n",
              "      <td>303.341669</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>98</th>\n",
              "      <td>0.10</td>\n",
              "      <td>0.10</td>\n",
              "      <td>0.0005</td>\n",
              "      <td>72000</td>\n",
              "      <td>302.286218</td>\n",
              "      <td>304.455138</td>\n",
              "      <td>329.108379</td>\n",
              "      <td>361.482108</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>99</th>\n",
              "      <td>0.10</td>\n",
              "      <td>0.10</td>\n",
              "      <td>0.0005</td>\n",
              "      <td>80000</td>\n",
              "      <td>301.944507</td>\n",
              "      <td>293.933018</td>\n",
              "      <td>311.063451</td>\n",
              "      <td>356.988049</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>100 rows  8 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "    recon_kl_w  recon_kl_clc  ...  fid_val_B2A  fid_val_B2A2B\n",
              "0         0.01          0.01  ...   197.646804     224.168804\n",
              "1         0.01          0.01  ...   174.118954     242.698832\n",
              "2         0.01          0.01  ...   176.418824     264.287935\n",
              "3         0.01          0.01  ...   169.634462     251.724293\n",
              "4         0.01          0.01  ...   171.687572     260.475951\n",
              "..         ...           ...  ...          ...            ...\n",
              "95        0.10          0.10  ...   316.374747     370.030933\n",
              "96        0.10          0.10  ...   227.174077     328.726003\n",
              "97        0.10          0.10  ...   198.270536     303.341669\n",
              "98        0.10          0.10  ...   329.108379     361.482108\n",
              "99        0.10          0.10  ...   311.063451     356.988049\n",
              "\n",
              "[100 rows x 8 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TBSiOpqYCRcw"
      },
      "source": [
        "FID_table = FID_table.assign(avg=FID_table.loc[:, [\"fid_val_A2B\", \"fid_val_A2B2A\", \"fid_val_B2A\", \"fid_val_B2A2B\"]].mean(axis=1))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8ygNb6HQyPxk"
      },
      "source": [
        "FID_table = FID_table.sort_values(by='avg')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EWi6H2EeEEgh"
      },
      "source": [
        "FID_table = FID_table.drop_duplicates()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wqr4xzkgxS0V"
      },
      "source": [
        "FID_table.to_csv(csv_output_folder + 'FID_with_average.csv', index=False)\n",
        "# FID_table = FID_table.dropna()\n",
        "# FID_table = FID_table.drop(columns=['fid_val_A2B.1'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 402
        },
        "id": "54jeCEvntLhi",
        "outputId": "6164eb33-bc08-4a40-cd3d-a7d4774ba350"
      },
      "source": [
        "FID_table"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>recon_kl_w</th>\n",
              "      <th>recon_kl_clc</th>\n",
              "      <th>lr_value</th>\n",
              "      <th>iteration</th>\n",
              "      <th>fid_val_A2B</th>\n",
              "      <th>fid_val_A2B2A</th>\n",
              "      <th>fid_val_B2A</th>\n",
              "      <th>fid_val_B2A2B</th>\n",
              "      <th>avg</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>70</th>\n",
              "      <td>0.10</td>\n",
              "      <td>0.10</td>\n",
              "      <td>0.0001</td>\n",
              "      <td>8000</td>\n",
              "      <td>203.910638</td>\n",
              "      <td>183.760694</td>\n",
              "      <td>183.209818</td>\n",
              "      <td>212.683878</td>\n",
              "      <td>195.891257</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>71</th>\n",
              "      <td>0.10</td>\n",
              "      <td>0.10</td>\n",
              "      <td>0.0001</td>\n",
              "      <td>16000</td>\n",
              "      <td>202.958507</td>\n",
              "      <td>200.343928</td>\n",
              "      <td>172.600639</td>\n",
              "      <td>234.167779</td>\n",
              "      <td>202.517713</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30</th>\n",
              "      <td>0.10</td>\n",
              "      <td>0.10</td>\n",
              "      <td>0.0001</td>\n",
              "      <td>8000</td>\n",
              "      <td>224.968845</td>\n",
              "      <td>210.204624</td>\n",
              "      <td>183.212693</td>\n",
              "      <td>212.631477</td>\n",
              "      <td>207.754410</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>92</th>\n",
              "      <td>0.10</td>\n",
              "      <td>0.10</td>\n",
              "      <td>0.0005</td>\n",
              "      <td>24000</td>\n",
              "      <td>204.744435</td>\n",
              "      <td>213.977543</td>\n",
              "      <td>178.736501</td>\n",
              "      <td>242.516149</td>\n",
              "      <td>209.993657</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>48</th>\n",
              "      <td>0.01</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.0005</td>\n",
              "      <td>72000</td>\n",
              "      <td>224.968845</td>\n",
              "      <td>210.204624</td>\n",
              "      <td>197.371917</td>\n",
              "      <td>208.524438</td>\n",
              "      <td>210.267456</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>98</th>\n",
              "      <td>0.10</td>\n",
              "      <td>0.10</td>\n",
              "      <td>0.0005</td>\n",
              "      <td>72000</td>\n",
              "      <td>302.286218</td>\n",
              "      <td>304.455138</td>\n",
              "      <td>329.108379</td>\n",
              "      <td>361.482108</td>\n",
              "      <td>324.332961</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>84</th>\n",
              "      <td>0.01</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.0005</td>\n",
              "      <td>40000</td>\n",
              "      <td>312.639646</td>\n",
              "      <td>316.967270</td>\n",
              "      <td>341.432377</td>\n",
              "      <td>348.106725</td>\n",
              "      <td>329.786504</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>85</th>\n",
              "      <td>0.01</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.0005</td>\n",
              "      <td>48000</td>\n",
              "      <td>303.227149</td>\n",
              "      <td>351.199004</td>\n",
              "      <td>311.179702</td>\n",
              "      <td>358.138596</td>\n",
              "      <td>330.936113</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>95</th>\n",
              "      <td>0.10</td>\n",
              "      <td>0.10</td>\n",
              "      <td>0.0005</td>\n",
              "      <td>48000</td>\n",
              "      <td>325.311955</td>\n",
              "      <td>328.068634</td>\n",
              "      <td>316.374747</td>\n",
              "      <td>370.030933</td>\n",
              "      <td>334.946567</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>80</th>\n",
              "      <td>0.01</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.0005</td>\n",
              "      <td>8000</td>\n",
              "      <td>396.100545</td>\n",
              "      <td>429.909908</td>\n",
              "      <td>348.621023</td>\n",
              "      <td>358.709496</td>\n",
              "      <td>383.335243</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>80 rows  9 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "    recon_kl_w  recon_kl_clc  lr_value  ...  fid_val_B2A  fid_val_B2A2B         avg\n",
              "70        0.10          0.10    0.0001  ...   183.209818     212.683878  195.891257\n",
              "71        0.10          0.10    0.0001  ...   172.600639     234.167779  202.517713\n",
              "30        0.10          0.10    0.0001  ...   183.212693     212.631477  207.754410\n",
              "92        0.10          0.10    0.0005  ...   178.736501     242.516149  209.993657\n",
              "48        0.01          0.01    0.0005  ...   197.371917     208.524438  210.267456\n",
              "..         ...           ...       ...  ...          ...            ...         ...\n",
              "98        0.10          0.10    0.0005  ...   329.108379     361.482108  324.332961\n",
              "84        0.01          0.01    0.0005  ...   341.432377     348.106725  329.786504\n",
              "85        0.01          0.01    0.0005  ...   311.179702     358.138596  330.936113\n",
              "95        0.10          0.10    0.0005  ...   316.374747     370.030933  334.946567\n",
              "80        0.01          0.01    0.0005  ...   348.621023     358.709496  383.335243\n",
              "\n",
              "[80 rows x 9 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    }
  ]
}